{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD6PB5zd0Zby"
      },
      "source": [
        "#<font color=yellow>15º Algoritmo Para 7 Espécies de Flores\n",
        "\n",
        "\n",
        "##Este código ajustado aumenta a complexidade da rede neural adicionando mais camadas convolucionais, mais neurônios e técnicas de regularização (Batch Normalization e Dropout) para melhorar as métricas de desempenho. Além disso, a exibição gráfica foi ajustada para um tamanho maior para melhor visualização, e uma tabela foi adicionada para mostrar a quantidade de imagens novas classificadas e as métricas de desempenho para cada classe de flor.\n",
        "\n",
        "##Além do citado no texto acima o caminho das imagens de flores para treino e teste da CNN e solicitado separadamente ao usuário para cada espécie de flor e em seguida após treinamento e teste e feito a solicitação do caminho para validação.\n",
        "\n",
        "##NOTA - O algoritmo após o carregamento das imagens de flores para treino e teste da CNN não começa a realizar o treinamento devido ao fato de exeder o uso da quantidade de memória RAM da IDE do Google Colab, logo serão feitas auterações no algoritmo para resolver este problema. Pode ser que isto tenha ocorrido devido ao fato do posicionamento da rede neural, onde o aumento de neurônios distribuidos nas camadas internas aumentava de forma crescente da camada de entrada até a camada de saída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvDQIfRq0ge7",
        "outputId": "954bf402-0ca1-4c9b-ffb0-d376dfca5367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Digite o caminho da pasta de treino para Margarida: /content/drive/MyDrive/Flores Treino/Margarida\n",
            "Digite o caminho da pasta de teste para Margarida: /content/drive/MyDrive/Flores Teste/Margarida\n",
            "Digite o caminho da pasta de treino para Dente de Leão: /content/drive/MyDrive/Flores Treino/Dente de Leão\n",
            "Digite o caminho da pasta de teste para Dente de Leão: /content/drive/MyDrive/Flores Teste/Dente de Leão\n",
            "Digite o caminho da pasta de treino para Rosa: /content/drive/MyDrive/Flores Treino/Rosa\n",
            "Digite o caminho da pasta de teste para Rosa: /content/drive/MyDrive/Flores Teste/Rosa\n",
            "Digite o caminho da pasta de treino para Girassol: /content/drive/MyDrive/Flores Treino/Girassol\n",
            "Digite o caminho da pasta de teste para Girassol: /content/drive/MyDrive/Flores Teste/Girassol\n",
            "Digite o caminho da pasta de treino para Tulipa: /content/drive/MyDrive/Flores Treino/Tulipa\n",
            "Digite o caminho da pasta de teste para Tulipa: /content/drive/MyDrive/Flores Teste/Tulipa\n",
            "Digite o caminho da pasta de treino para Campânula: /content/drive/MyDrive/Flores Treino/Campânula\n",
            "Digite o caminho da pasta de teste para Campânula: /content/drive/MyDrive/Flores Teste/Campânula\n",
            "Digite o caminho da pasta de treino para Lótus: /content/drive/MyDrive/Flores Treino/Lótus\n",
            "Digite o caminho da pasta de teste para Lótus: /content/drive/MyDrive/Flores Teste/Lótus\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    balanced_accuracy_score,\n",
        "    precision_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    precision_recall_curve,\n",
        ")\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Defina as dimensões das imagens\n",
        "img_height = 150\n",
        "img_width = 150\n",
        "num_classes = 7  # Sete classes para diferentes tipos de flores\n",
        "\n",
        "# Dicionário de rótulos para cada tipo de flor\n",
        "flower_labels = {\n",
        "    \"Margarida\": 0,\n",
        "    \"Dente de Leão\": 1,\n",
        "    \"Rosa\": 2,\n",
        "    \"Girassol\": 3,\n",
        "    \"Tulipa\": 4,\n",
        "    \"Campânula\": 5,\n",
        "    \"Lótus\": 6,\n",
        "}\n",
        "\n",
        "def carregar_imagens_do_drive(caminho_pasta, flower_type):\n",
        "    data = []\n",
        "    labels = []\n",
        "    if not os.path.exists(caminho_pasta):\n",
        "        print(f\"Erro: A pasta {caminho_pasta} não existe.\")\n",
        "        return data, labels\n",
        "    for filename in os.listdir(caminho_pasta):\n",
        "        img_path = os.path.join(caminho_pasta, filename)\n",
        "        try:\n",
        "            img = Image.open(img_path).resize((img_height, img_width)).convert('RGB')\n",
        "            img_array = np.array(img)\n",
        "            data.append(img_array)\n",
        "            labels.append(flower_labels[flower_type])\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar imagem {img_path}: {e}\")\n",
        "    return data, labels\n",
        "\n",
        "def carregar_todas_as_imagens():\n",
        "    train_data = []\n",
        "    train_labels = []\n",
        "    val_data = []\n",
        "    val_labels = []\n",
        "\n",
        "    for flower_type in flower_labels.keys():\n",
        "        caminho_treino = input(f\"Digite o caminho da pasta de treino para {flower_type}: \")\n",
        "        caminho_teste = input(f\"Digite o caminho da pasta de teste para {flower_type}: \")\n",
        "\n",
        "        data_treino, labels_treino = carregar_imagens_do_drive(caminho_treino, flower_type)\n",
        "        data_teste, labels_teste = carregar_imagens_do_drive(caminho_teste, flower_type)\n",
        "\n",
        "        train_data.extend(data_treino)\n",
        "        train_labels.extend(labels_treino)\n",
        "        val_data.extend(data_teste)\n",
        "        val_labels.extend(labels_teste)\n",
        "\n",
        "    return np.array(train_data), np.array(train_labels), np.array(val_data), np.array(val_labels)\n",
        "\n",
        "# Carregar e processar as imagens para treinamento e validação\n",
        "train_data, train_labels, val_data, val_labels = carregar_todas_as_imagens()\n",
        "\n",
        "# Normalizar os dados de imagem\n",
        "train_data = train_data / 255.0\n",
        "val_data = val_data / 255.0\n",
        "\n",
        "# ********************* IMPLEMENTAÇÃO DA REDE NEURAL ARTIFICIAL CNN LENET-5 **************************************************\n",
        "\n",
        "# Construir o modelo LeNet-5 adaptado e aprimorado\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", input_shape=(img_height, img_width, 3), padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=50, batch_size=32)\n",
        "\n",
        "# ********************* FIM DO BLOCO DE CÓDIGO COM A REDE NEURAL CNN***************************************************\n",
        "\n",
        "# Avaliar o modelo nos dados de teste\n",
        "test_loss, test_accuracy = model.evaluate(val_data, val_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Prever as classes para os dados de teste\n",
        "test_predictions = model.predict(val_data)\n",
        "test_predictions_classes = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Salvar o modelo na pasta de downloads\n",
        "model.save(\"/content/drive/My Drive/flower_classification_model.h5\")\n",
        "\n",
        "# Plotando gráfico de matriz de confusão para imagens de teste\n",
        "confusion = confusion_matrix(val_labels, test_predictions_classes)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(\n",
        "    confusion,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=False,\n",
        "    xticklabels=flower_labels.keys(),\n",
        "    yticklabels=flower_labels.keys(),\n",
        ")\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Atual\")\n",
        "plt.title(\"Matriz de Confusão para Imagens de Teste\")\n",
        "plt.show()\n",
        "\n",
        "# Calculando métricas de validação para imagens de teste\n",
        "accuracy = accuracy_score(val_labels, test_predictions_classes)\n",
        "balanced_accuracy = balanced_accuracy_score(val_labels, test_predictions_classes)\n",
        "precision = precision_score(val_labels, test_predictions_classes, average='weighted')\n",
        "f1 = f1_score(val_labels, test_predictions_classes, average='weighted')\n",
        "recall = recall_score(val_labels, test_predictions_classes, average='weighted')\n",
        "\n",
        "print(\"Acurácia para imagens de teste:\", accuracy)\n",
        "print(\"Acurácia Balanceada para imagens de teste:\", balanced_accuracy)\n",
        "print(\"Precisão para imagens de teste:\", precision)\n",
        "print(\"F1 Score para imagens de teste:\", f1)\n",
        "print(\"Recall para imagens de teste:\", recall)\n",
        "\n",
        "# Plotar gráficos de perda e acurácia\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "# Gráfico de perda\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de acurácia\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Transformar o problema em binário para uma abordagem \"one-vs-rest\"\n",
        "for class_index in range(num_classes):\n",
        "    print(f\"\\nClasse: {list(flower_labels.keys())[class_index]}\")\n",
        "\n",
        "    # Extrair rótulos binários para a classe atual\n",
        "    binary_labels = (val_labels == class_index).astype(int)\n",
        "\n",
        "    # Calcular probabilidades previstas para a classe atual\n",
        "    predicted_probabilities = test_predictions[:, class_index]\n",
        "\n",
        "    # Curva Precision-Recall\n",
        "    precision, recall, thresholds = precision_recall_curve(binary_labels, predicted_probabilities)\n",
        "\n",
        "    # F1-score para diferentes limiares de probabilidade\n",
        "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
        "\n",
        "    # Limiar que maximiza o F1-score\n",
        "    optimal_threshold_index = np.argmax(f1_scores)\n",
        "\n",
        "    # Limiar ótimo\n",
        "    optimal_threshold = thresholds[optimal_threshold_index]\n",
        "    optimal_precision = precision[optimal_threshold_index]\n",
        "    optimal_recall = recall[optimal_threshold_index]\n",
        "\n",
        "    print(\"Limiar ótimo que maximiza o F1-score (otimizando tanto a Precisão quanto o Recall):\", optimal_threshold)\n",
        "    print(\"Precisão ótima:\", optimal_precision)\n",
        "    print(\"Recall ótimo:\", optimal_recall)\n",
        "\n",
        "    # Plotando precision-recall curve\n",
        "    plt.figure(figsize=(18, 10))\n",
        "\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.plot(recall, precision, marker='.', label=f'Precision-Recall Curve for {list(flower_labels.keys())[class_index]}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(f'Precision-Recall Curve for {list(flower_labels.keys())[class_index]}')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotando precision VS threshold e recall VS threshold\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.plot(thresholds, precision[:-1], label='Precision', color='blue')\n",
        "    plt.plot(thresholds, recall[:-1], label='Recall', color='green')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Value')\n",
        "    plt.title(f'Precision and Recall vs. Threshold for {list(flower_labels.keys())[class_index]}')\n",
        "    plt.axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal Threshold ({optimal_threshold:.3f})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotando F1-score VS threshold\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.plot(thresholds, f1_scores[:-1], label='F1 Score', color='orange')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title(f'F1 Score vs. Threshold for {list(flower_labels.keys())[class_index]}')\n",
        "    plt.axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal Threshold ({optimal_threshold:.3f})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotando curva ROC e AUC\n",
        "    plt.subplot(2, 3, 4)\n",
        "    fpr, tpr, _ = roc_curve(binary_labels, predicted_probabilities)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {list(flower_labels.keys())[class_index]}')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Função para identificar e exibir novas imagens\n",
        "def identificar_e_exibir_imagens():\n",
        "    caminho_novas_imagens = input(\"Digite o caminho da pasta de novas imagens no Google Drive: \")\n",
        "\n",
        "    new_images = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(caminho_novas_imagens):\n",
        "        img_path = os.path.join(caminho_novas_imagens, filename)\n",
        "        img = Image.open(img_path).resize((img_height, img_width)).convert('RGB')\n",
        "        img_array = np.array(img)\n",
        "        new_images.append(img_array)\n",
        "        filenames.append(filename)\n",
        "\n",
        "    if not new_images:\n",
        "        print(\"Nenhuma imagem carregada.\")\n",
        "        return\n",
        "\n",
        "    new_images = np.array(new_images) / 255.0\n",
        "\n",
        "    predictions = model.predict(new_images)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    confidences = np.max(predictions, axis=1) * 100\n",
        "\n",
        "    num_cols = 5\n",
        "    num_rows = (len(new_images) + num_cols - 1) // num_cols  # Calcular o número de linhas necessário\n",
        "\n",
        "    plt.figure(figsize=(20, num_rows * 4))  # Ajustar o tamanho da figura\n",
        "\n",
        "    for i, (filename, predicted_class, confidence) in enumerate(zip(filenames, predicted_classes, confidences)):\n",
        "        plt.subplot(num_rows, num_cols, i + 1)\n",
        "        img = Image.open(os.path.join(caminho_novas_imagens, filename))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'{list(flower_labels.keys())[predicted_class]} ({confidence:.2f}%)')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Exibir quantidade de imagens novas classificadas e percentual de acurácia e precisão\n",
        "    total_images = len(new_images)\n",
        "    class_counts = np.bincount(predicted_classes, minlength=num_classes)\n",
        "    class_accuracies = [np.sum(predicted_classes == i) / total_images for i in range(num_classes)]\n",
        "    class_precisions = [precision_score(new_images, predicted_classes == i, average='weighted') for i in range(num_classes)]\n",
        "\n",
        "    table_data = {\n",
        "        \"Classe de Flor\": list(flower_labels.keys()),\n",
        "        \"Quantidade Classificada\": class_counts,\n",
        "        \"Acurácia (%)\": [acc * 100 for acc in class_accuracies],\n",
        "        \"Precisão (%)\": [prec * 100 for prec in class_precisions],\n",
        "    }\n",
        "    df = pd.DataFrame(table_data)\n",
        "\n",
        "    print(\"\\nTabela de Classificação de Imagens Novas:\")\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "# Função para o loop principal de identificação de imagens\n",
        "def main_loop():\n",
        "    while True:\n",
        "        identificar_e_exibir_imagens()\n",
        "        action = input(\"Digite 'novas' para identificar outras imagens ou 'sair' para terminar: \").lower()\n",
        "        if action == 'sair':\n",
        "            print(\"Encerrando o programa.\")\n",
        "            break\n",
        "\n",
        "# Chamar a função para identificar novas imagens\n",
        "main_loop()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}